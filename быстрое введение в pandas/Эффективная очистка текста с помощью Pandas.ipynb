{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Эффективная очистка текста с помощью Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/dm-fedorov/pandas_basic/blob/master/%D0%BA%D0%B5%D0%B9%D1%81%D1%8B%20%D0%BF%D0%BE%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D1%83%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/0.%20%D0%9C%D0%B0%D1%80%D0%BA%D0%B5%D1%82%D0%B8%D0%BD%D0%B3.ipynb\" target=\"_blank\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вступление\n",
    "\n",
    "Очистка данных занимает значительную часть процесса анализа данных. При использовании *pandas* существует несколько методов очистки текстовых полей для подготовки к дальнейшему анализу. По мере того, как наборы данных увеличиваются, важно использовать эффективные методы.\n",
    "\n",
    "В этой статье будут показаны примеры очистки текстовых полей в большом файле и даны советы по эффективной очистке неструктурированных текстовых полей с помощью *Python* и *pandas*.\n",
    "\n",
    "> Оригинал статьи Криса по [ссылке](https://pbpython.com/text-cleaning.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проблема\n",
    "\n",
    "Предположим, что у вас есть новый крафтовый виски, который вы хотели бы продать. Ваша территория включает Айову, и там есть [открытый набор данных](https://data.iowa.gov/Sales-Distribution/Iowa-Liquor-Sales/m3tr-qhgy), который показывает продажи спиртных напитков в штате. Это кажется отличной возможностью, чтобы посмотреть, у кого самые большие счета в штате. Вооружившись этими данными, можно спланировать процесс продаж в магазины.\n",
    "\n",
    "В восторге от этой возможности, вы загружаете данные и понимаете, что они довольно большие. В этой статье я буду использовать данные, включающие продажи за `2019 год`. \n",
    "\n",
    "Выборочный набор данных представляет собой CSV-файл размером `565 МБ` с `24` столбцами и `2,3 млн` строк, а весь датасет занимает `5 Гб` (`25 млн` строк). Это ни в коем случае не большие данные, но они достаточно большие для обработки в *Excel* и некоторых методов *pandas*.\n",
    "\n",
    "Давайте начнем с импорта модулей и чтения данных. \n",
    "\n",
    "Я также воспользуюсь пакетом [`sidetable`](https://dfedorov.spb.ru/pandas/%D0%A1%D0%BE%D0%B7%D0%B4%D0%B0%D0%BD%D0%B8%D0%B5%20%D0%BF%D1%80%D0%BE%D1%81%D1%82%D1%8B%D1%85%20%D1%81%D0%B2%D0%BE%D0%B4%D0%BD%D1%8B%D1%85%20%D1%82%D0%B0%D0%B1%D0%BB%D0%B8%D1%86%20%D0%B2%20pandas%20%D1%81%20%D0%BF%D0%BE%D0%BC%D0%BE%D1%89%D1%8C%D1%8E%20sidetable.html) для обобщения данных. Он не требуется для очистки, но может быть полезен для подобных сценариев исследования данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install sidetable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные\n",
    "\n",
    "Загрузим данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sidetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/9e88whmc03nkouz/2019_Iowa_Liquor_Sales.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2019_Iowa_Liquor_Sales.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на них:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Invoice/Item Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Store Number</th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Store Location</th>\n",
       "      <th>County Number</th>\n",
       "      <th>County</th>\n",
       "      <th>...</th>\n",
       "      <th>Item Number</th>\n",
       "      <th>Item Description</th>\n",
       "      <th>Pack</th>\n",
       "      <th>Bottle Volume (ml)</th>\n",
       "      <th>State Bottle Cost</th>\n",
       "      <th>State Bottle Retail</th>\n",
       "      <th>Bottles Sold</th>\n",
       "      <th>Sale (Dollars)</th>\n",
       "      <th>Volume Sold (Liters)</th>\n",
       "      <th>Volume Sold (Gallons)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INV-16681900011</td>\n",
       "      <td>01/02/2019</td>\n",
       "      <td>5286</td>\n",
       "      <td>Sauce</td>\n",
       "      <td>108, College</td>\n",
       "      <td>Iowa City</td>\n",
       "      <td>52240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>JOHNSON</td>\n",
       "      <td>...</td>\n",
       "      <td>48099</td>\n",
       "      <td>Hennessy VS</td>\n",
       "      <td>24</td>\n",
       "      <td>200</td>\n",
       "      <td>6.24</td>\n",
       "      <td>9.36</td>\n",
       "      <td>24</td>\n",
       "      <td>224.64</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INV-16681900027</td>\n",
       "      <td>01/02/2019</td>\n",
       "      <td>5286</td>\n",
       "      <td>Sauce</td>\n",
       "      <td>108, College</td>\n",
       "      <td>Iowa City</td>\n",
       "      <td>52240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>JOHNSON</td>\n",
       "      <td>...</td>\n",
       "      <td>89191</td>\n",
       "      <td>Jose Cuervo Especial Reposado Mini</td>\n",
       "      <td>12</td>\n",
       "      <td>500</td>\n",
       "      <td>11.50</td>\n",
       "      <td>17.25</td>\n",
       "      <td>12</td>\n",
       "      <td>207.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INV-16681900018</td>\n",
       "      <td>01/02/2019</td>\n",
       "      <td>5286</td>\n",
       "      <td>Sauce</td>\n",
       "      <td>108, College</td>\n",
       "      <td>Iowa City</td>\n",
       "      <td>52240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>JOHNSON</td>\n",
       "      <td>...</td>\n",
       "      <td>8824</td>\n",
       "      <td>Lauder's</td>\n",
       "      <td>24</td>\n",
       "      <td>375</td>\n",
       "      <td>3.21</td>\n",
       "      <td>4.82</td>\n",
       "      <td>24</td>\n",
       "      <td>115.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INV-16685400036</td>\n",
       "      <td>01/02/2019</td>\n",
       "      <td>2524</td>\n",
       "      <td>Hy-Vee Food Store / Dubuque</td>\n",
       "      <td>3500 Dodge St</td>\n",
       "      <td>Dubuque</td>\n",
       "      <td>52001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>DUBUQUE</td>\n",
       "      <td>...</td>\n",
       "      <td>35917</td>\n",
       "      <td>Five O'Clock Vodka</td>\n",
       "      <td>12</td>\n",
       "      <td>1000</td>\n",
       "      <td>4.17</td>\n",
       "      <td>6.26</td>\n",
       "      <td>12</td>\n",
       "      <td>75.12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INV-16690300035</td>\n",
       "      <td>01/02/2019</td>\n",
       "      <td>4449</td>\n",
       "      <td>Kum &amp; Go #121 / Urbandale</td>\n",
       "      <td>12041 Douglas Pkwy</td>\n",
       "      <td>Urbandale</td>\n",
       "      <td>50322.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.0</td>\n",
       "      <td>POLK</td>\n",
       "      <td>...</td>\n",
       "      <td>36304</td>\n",
       "      <td>Hawkeye Vodka</td>\n",
       "      <td>24</td>\n",
       "      <td>375</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.79</td>\n",
       "      <td>24</td>\n",
       "      <td>66.96</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Invoice/Item Number        Date  Store Number                   Store Name  \\\n",
       "0     INV-16681900011  01/02/2019          5286                        Sauce   \n",
       "1     INV-16681900027  01/02/2019          5286                        Sauce   \n",
       "2     INV-16681900018  01/02/2019          5286                        Sauce   \n",
       "3     INV-16685400036  01/02/2019          2524  Hy-Vee Food Store / Dubuque   \n",
       "4     INV-16690300035  01/02/2019          4449    Kum & Go #121 / Urbandale   \n",
       "\n",
       "              Address       City  Zip Code Store Location  County Number  \\\n",
       "0        108, College  Iowa City   52240.0            NaN           52.0   \n",
       "1        108, College  Iowa City   52240.0            NaN           52.0   \n",
       "2        108, College  Iowa City   52240.0            NaN           52.0   \n",
       "3       3500 Dodge St    Dubuque   52001.0            NaN           31.0   \n",
       "4  12041 Douglas Pkwy  Urbandale   50322.0            NaN           77.0   \n",
       "\n",
       "    County  ...  Item Number                    Item Description  Pack  \\\n",
       "0  JOHNSON  ...        48099                         Hennessy VS    24   \n",
       "1  JOHNSON  ...        89191  Jose Cuervo Especial Reposado Mini    12   \n",
       "2  JOHNSON  ...         8824                            Lauder's    24   \n",
       "3  DUBUQUE  ...        35917                  Five O'Clock Vodka    12   \n",
       "4     POLK  ...        36304                       Hawkeye Vodka    24   \n",
       "\n",
       "  Bottle Volume (ml)  State Bottle Cost State Bottle Retail  Bottles Sold  \\\n",
       "0                200               6.24                9.36            24   \n",
       "1                500              11.50               17.25            12   \n",
       "2                375               3.21                4.82            24   \n",
       "3               1000               4.17                6.26            12   \n",
       "4                375               1.86                2.79            24   \n",
       "\n",
       "   Sale (Dollars)  Volume Sold (Liters)  Volume Sold (Gallons)  \n",
       "0          224.64                   4.8                   1.26  \n",
       "1          207.00                   6.0                   1.58  \n",
       "2          115.68                   9.0                   2.37  \n",
       "3           75.12                  12.0                   3.17  \n",
       "4           66.96                   9.0                   2.37  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первое, что можно сделать, это посмотреть, сколько закупает каждый магазин, и отсортировать их по убыванию. У нас ограниченные ресурсы, поэтому мы должны сосредоточиться на тех местах, где мы получим максимальную отдачу от вложенных средств. Нам будет проще позвонить паре крупных корпоративных клиентов, чем множеству семейных магазинов.\n",
    "\n",
    "Модуль [`sidetable`](https://dfedorov.spb.ru/pandas/%D0%A1%D0%BE%D0%B7%D0%B4%D0%B0%D0%BD%D0%B8%D0%B5%20%D0%BF%D1%80%D0%BE%D1%81%D1%82%D1%8B%D1%85%20%D1%81%D0%B2%D0%BE%D0%B4%D0%BD%D1%8B%D1%85%20%D1%82%D0%B0%D0%B1%D0%BB%D0%B8%D1%86%20%D0%B2%20pandas%20%D1%81%20%D0%BF%D0%BE%D0%BC%D0%BE%D1%89%D1%8C%D1%8E%20sidetable.html) позволяет обобщать данные в удобочитаемом формате и является альтернативой методу `groupby` с дополнительными преобразованиями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.stb.freq(['Store Name'], value='Sale (Dollars)', style=True, cum_cols=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Похоже, во всех трех случаях  \n",
    "\n",
    "- `Hy-Vee #3 / BDI / Des Moines`\n",
    "- `Hy-Vee Wine and Spirits / Iowa City`\n",
    "- `Hy-Vee Food Store / Urbandale`\n",
    "\n",
    "речь идет об одном и том же магазине. Очевидно, что названия магазинов в большинстве случаев уникальны для каждого местоположения. \n",
    "\n",
    "В идеале мы хотели бы сгруппировать вместе все продажи `Hy-Vee`, `Costco` и т.д.\n",
    "\n",
    "Нам нужно очистить данные!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попытка очистки №1\n",
    "\n",
    "Первый подход, который мы рассмотрим, - это использование `.loc` плюс логический фильтр с аксессором `str` для поиска соответствующей строки в столбце `Store Name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Store Name'].str.contains('Hy-Vee', case=False), 'Store_Group_1'] = 'Hy-Vee'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот код будет искать строку `Hy-Vee` без учета регистра и сохранять значение `Hy-Vee` в новом столбце с именем `Store_Group_1`. Данный код эффективно преобразует такие названия, как `Hy-Vee # 3 / BDI / Des Moines` или `Hy-Vee Food Store / Urbandale`, в обычное `Hy-Vee`.\n",
    "\n",
    "Вот, что `%timeit` говорит об эффективности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.52 s ± 11.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit df.loc[df['Store Name'].str.contains('Hy-Vee', case=False), 'Store_Group_1'] = 'Hy-Vee'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем использовать параметр `regex=False` для ускорения вычислений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811 ms ± 5.96 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit df.loc[df['Store Name'].str.contains('Hy-Vee', case=False, regex=False), 'Store_Group_1'] = 'Hy-Vee'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот значения в новом столбце:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN       1617777\n",
       "Hy-Vee     762568\n",
       "Name: Store_Group_1, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Store_Group_1'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы очистили `Hy-Vee`, но теперь появилось множество других значений, с которыми нам нужно разобраться.\n",
    "\n",
    "Подход `.loc` включает много кода и может быть медленным. Поищем альтернативы, которые быстрее выполнять и легче поддерживать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попытка очистки №2\n",
    "\n",
    "Другой очень эффективный и гибкий подход - использовать `np.select` для запуска нескольких совпадений и применения указанного значения при совпадении.\n",
    "\n",
    "Есть несколько хороших ресурсов, которые я использовал, чтобы узнать про `np.select`. Эта [статья](https://www.dataquest.io/blog/tutorial-add-column-pandas-dataframe-based-on-if-else-condition/) от *Dataquest* - хороший обзор, а также [презентация](https://docs.google.com/presentation/d/1X7CheRfv0n4_I21z4bivvsHt6IDxkuaiAuCclSzia1E/edit#slide=id.g635adc05c1_1_1840) Натана Чивера (*Nathan Cheever*). Рекомендую и то, и другое.\n",
    "\n",
    "Самое простое объяснение того, что делает `np.select`, состоит в том, что он оценивает список условий и применяет соответствующий список значений, если условие истинно.\n",
    "\n",
    "В нашем случае условиями будут разные строки для поиски (*string lookups*), а в качестве значений нормализованные строки, которые хотим использовать.\n",
    "\n",
    "После просмотра данных, вот список условий и значений в списке `store_patterns`. Каждый кортеж в этом списке представляет собой поиск по `str.contains()` и соответствующее текстовое значение, которое мы хотим использовать для группировки похожих счетов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_patterns = [\n",
    "    (df['Store Name'].str.contains('Hy-Vee', case=False, regex=False), 'Hy-Vee'),\n",
    "    (df['Store Name'].str.contains('Central City', case=False,  regex=False), 'Central City'),\n",
    "    (df['Store Name'].str.contains(\"Smokin' Joe's\", case=False,  regex=False), \"Smokin' Joe's\"),\n",
    "    (df['Store Name'].str.contains('Walmart|Wal-Mart', case=False), 'Wal-Mart'),\n",
    "    (df['Store Name'].str.contains('Fareway Stores', case=False,  regex=False), 'Fareway Stores'),\n",
    "    (df['Store Name'].str.contains(\"Casey's\", case=False,  regex=False), \"Casey's General Store\"),\n",
    "    (df['Store Name'].str.contains(\"Sam's Club\", case=False,  regex=False), \"Sam's Club\"),\n",
    "    (df['Store Name'].str.contains('Kum & Go', regex=False, case=False), 'Kum & Go'),\n",
    "    (df['Store Name'].str.contains('CVS', regex=False, case=False), 'CVS Pharmacy'),\n",
    "    (df['Store Name'].str.contains('Walgreens', regex=False, case=False), 'Walgreens'),\n",
    "    (df['Store Name'].str.contains('Yesway', regex=False, case=False), 'Yesway Store'),\n",
    "    (df['Store Name'].str.contains('Target Store', regex=False, case=False), 'Target'),\n",
    "    (df['Store Name'].str.contains('Quik Trip', regex=False, case=False), 'Quik Trip'),\n",
    "    (df['Store Name'].str.contains('Circle K', regex=False, case=False), 'Circle K'),\n",
    "    (df['Store Name'].str.contains('Hometown Foods', regex=False, case=False), 'Hometown Foods'),\n",
    "    (df['Store Name'].str.contains(\"Bucky's\", case=False, regex=False), \"Bucky's Express\"),\n",
    "    (df['Store Name'].str.contains('Kwik', case=False, regex=False), 'Kwik Shop')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна из серьезных проблем при работе с `np.select` заключается в том, что легко получить несоответствие условий и значений. Я решил объединить в кортеж, чтобы упростить отслеживание совпадений данных.\n",
    "\n",
    "Из-за такой структуры приходится разбивать список кортежей на два отдельных списка. \n",
    "\n",
    "Используя `zip`, можем взять `store_patterns` и разбить его на `store_criteria` и `store_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_criteria, store_values = zip(*store_patterns)\n",
    "df['Store_Group_1'] = np.select(store_criteria, store_values, 'other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот код будет заполнять каждое совпадение текстовым значением. Если совпадений нет, то присвоим ему значение `other`.\n",
    "\n",
    "Вот как это выглядит сейчас:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_4a971_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Store_Group_1</th>        <th class=\"col_heading level0 col1\" >Sale (Dollars)</th>        <th class=\"col_heading level0 col2\" >percent</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_4a971_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_4a971_row0_col0\" class=\"data row0 col0\" >Hy-Vee</td>\n",
       "                        <td id=\"T_4a971_row0_col1\" class=\"data row0 col1\" >126,265,195</td>\n",
       "                        <td id=\"T_4a971_row0_col2\" class=\"data row0 col2\" >36.16%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4a971_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_4a971_row1_col0\" class=\"data row1 col0\" >other</td>\n",
       "                        <td id=\"T_4a971_row1_col1\" class=\"data row1 col1\" >112,733,367</td>\n",
       "                        <td id=\"T_4a971_row1_col2\" class=\"data row1 col2\" >32.28%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4a971_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_4a971_row2_col0\" class=\"data row2 col0\" >Fareway Stores</td>\n",
       "                        <td id=\"T_4a971_row2_col1\" class=\"data row2 col1\" >23,146,939</td>\n",
       "                        <td id=\"T_4a971_row2_col2\" class=\"data row2 col2\" >6.63%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4a971_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_4a971_row3_col0\" class=\"data row3 col0\" >Wal-Mart</td>\n",
       "                        <td id=\"T_4a971_row3_col1\" class=\"data row3 col1\" >22,641,682</td>\n",
       "                        <td id=\"T_4a971_row3_col2\" class=\"data row3 col2\" >6.48%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4a971_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_4a971_row4_col0\" class=\"data row4 col0\" >Sam's Club</td>\n",
       "                        <td id=\"T_4a971_row4_col1\" class=\"data row4 col1\" >19,604,085</td>\n",
       "                        <td id=\"T_4a971_row4_col2\" class=\"data row4 col2\" >5.61%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4a971_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_4a971_row5_col0\" class=\"data row5 col0\" >Central City</td>\n",
       "                        <td id=\"T_4a971_row5_col1\" class=\"data row5 col1\" >14,108,944</td>\n",
       "                        <td id=\"T_4a971_row5_col2\" class=\"data row5 col2\" >4.04%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4a971_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_4a971_row6_col0\" class=\"data row6 col0\" >Casey's General Store</td>\n",
       "                        <td id=\"T_4a971_row6_col1\" class=\"data row6 col1\" >11,351,935</td>\n",
       "                        <td id=\"T_4a971_row6_col2\" class=\"data row6 col2\" >3.25%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4a971_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_4a971_row7_col0\" class=\"data row7 col0\" >Kum & Go</td>\n",
       "                        <td id=\"T_4a971_row7_col1\" class=\"data row7 col1\" >6,019,449</td>\n",
       "                        <td id=\"T_4a971_row7_col2\" class=\"data row7 col2\" >1.72%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4a971_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_4a971_row8_col0\" class=\"data row8 col0\" >Walgreens</td>\n",
       "                        <td id=\"T_4a971_row8_col1\" class=\"data row8 col1\" >2,942,270</td>\n",
       "                        <td id=\"T_4a971_row8_col2\" class=\"data row8 col2\" >0.84%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4a971_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_4a971_row9_col0\" class=\"data row9 col0\" >Target</td>\n",
       "                        <td id=\"T_4a971_row9_col1\" class=\"data row9 col1\" >2,904,611</td>\n",
       "                        <td id=\"T_4a971_row9_col2\" class=\"data row9 col2\" >0.83%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4a971_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_4a971_row10_col0\" class=\"data row10 col0\" >Smokin' Joe's</td>\n",
       "                        <td id=\"T_4a971_row10_col1\" class=\"data row10 col1\" >2,049,536</td>\n",
       "                        <td id=\"T_4a971_row10_col2\" class=\"data row10 col2\" >0.59%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4a971_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "                        <td id=\"T_4a971_row11_col0\" class=\"data row11 col0\" >Kwik Shop</td>\n",
       "                        <td id=\"T_4a971_row11_col1\" class=\"data row11 col1\" >1,431,142</td>\n",
       "                        <td id=\"T_4a971_row11_col2\" class=\"data row11 col2\" >0.41%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4a971_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "                        <td id=\"T_4a971_row12_col0\" class=\"data row12 col0\" >Quik Trip</td>\n",
       "                        <td id=\"T_4a971_row12_col1\" class=\"data row12 col1\" >1,140,374</td>\n",
       "                        <td id=\"T_4a971_row12_col2\" class=\"data row12 col2\" >0.33%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4a971_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "                        <td id=\"T_4a971_row13_col0\" class=\"data row13 col0\" >CVS Pharmacy</td>\n",
       "                        <td id=\"T_4a971_row13_col1\" class=\"data row13 col1\" >795,303</td>\n",
       "                        <td id=\"T_4a971_row13_col2\" class=\"data row13 col2\" >0.23%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4a971_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "                        <td id=\"T_4a971_row14_col0\" class=\"data row14 col0\" >Hometown Foods</td>\n",
       "                        <td id=\"T_4a971_row14_col1\" class=\"data row14 col1\" >787,840</td>\n",
       "                        <td id=\"T_4a971_row14_col2\" class=\"data row14 col2\" >0.23%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4a971_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "                        <td id=\"T_4a971_row15_col0\" class=\"data row15 col0\" >Yesway Store</td>\n",
       "                        <td id=\"T_4a971_row15_col1\" class=\"data row15 col1\" >741,863</td>\n",
       "                        <td id=\"T_4a971_row15_col2\" class=\"data row15 col2\" >0.21%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4a971_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "                        <td id=\"T_4a971_row16_col0\" class=\"data row16 col0\" >Bucky's Express</td>\n",
       "                        <td id=\"T_4a971_row16_col1\" class=\"data row16 col1\" >465,757</td>\n",
       "                        <td id=\"T_4a971_row16_col2\" class=\"data row16 col2\" >0.13%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4a971_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "                        <td id=\"T_4a971_row17_col0\" class=\"data row17 col0\" >Circle K</td>\n",
       "                        <td id=\"T_4a971_row17_col1\" class=\"data row17 col1\" >90,049</td>\n",
       "                        <td id=\"T_4a971_row17_col2\" class=\"data row17 col2\" >0.03%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff2046581f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stb.freq(['Store_Group_1'], value='Sale (Dollars)', style=True, cum_cols=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так лучше, но `32,28%` выручки по-прежнему приходится на `other` счета.\n",
    "\n",
    "Далее, если есть счет, который не соответствует шаблону, то используем `Store Name` вместо того, чтобы объединять все в `other`. \n",
    "\n",
    "Вот как мы это сделаем:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Store_Group_1'] = np.select(store_criteria, store_values, None)\n",
    "df['Store_Group_1'] = df['Store_Group_1'].combine_first(df['Store Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь используется функция `comb_first`, чтобы заполнить все `None` значения `Store Name`. Это удобный прием, о котором следует помнить при очистке данных.\n",
    "\n",
    "Проверим наши данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.stb.freq(['Store_Group_1'], value='Sale (Dollars)', style=True, cum_cols=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выглядит лучше, т.к. можем продолжать уточнять группировки по мере необходимости. Например, можно построить поиск по строке для `Costco`.\n",
    "\n",
    "Производительность не так уж и плоха для большого набора данных:\n",
    "\n",
    "    13.2 s ± 328 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "Гибкость данного подхода в том, что можно использовать `np.select` для числового анализа и текстовых примеров.\n",
    "\n",
    "Единственная проблема, связанная с этим подходом, заключается в большом количестве кода. \n",
    "\n",
    "Есть ли другой подход, который мог бы иметь аналогичную производительность, но был бы немного чище?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попытка очистки №3\n",
    "\n",
    "Следующее решение основано на [этом](https://www.metasnake.com/blog/pydata-assign.html) примере кода от Мэтта Харрисона (*Matt Harrison*). Он разработал функцию `generalize`, которая выполняет сопоставление и очистку за нас! \n",
    "\n",
    "Я внес некоторые изменения, чтобы привести ее в соответствие с этим примером, но хочу отдать должное Мэтту. Я бы никогда не подумал об этом решении, если бы оно не выполняло `99%` всей работы!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalize(ser, match_name, default=None, regex=False, case=False):\n",
    "    \"\"\" Поиск в серии текстовых совпадений.\n",
    "    На основе кода из https://www.metasnake.com/blog/pydata-assign.html\n",
    "\n",
    "    ser: серии pandas для поиска \n",
    "    match_name: кортеж, содержащий текст для поиска и текст для нормализации\n",
    "    default: Если совпадений нет, используйте это, чтобы указать значение по умолчанию, \n",
    "    в противном случае используйте оригинальный текст\n",
    "    regex: Логическое значение, указывающее, содержит ли match_name регулярное выражение\n",
    "    case: Поиск с учетом регистра\n",
    "\n",
    "    Возвращает серию pandas с совпадающим значением\n",
    "    \"\"\"\n",
    "    seen = None\n",
    "    for match, name in match_name:\n",
    "        mask = ser.str.contains(match, case=case, regex=regex)\n",
    "        if seen is None:\n",
    "            seen = mask\n",
    "        else:\n",
    "            seen |= mask\n",
    "        ser = ser.where(~mask, name)\n",
    "    if default:\n",
    "        ser = ser.where(seen, default)\n",
    "    else:\n",
    "        ser = ser.where(seen, ser.values)\n",
    "    return ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта функция может быть вызвана для серии *pandas* и ожидает список кортежей. \n",
    "\n",
    "Первый элемент следующего кортежа - это значение для поиска, а второй - значение, которое нужно заполнить для совпадающего значения.\n",
    "\n",
    "Вот список эквивалентных шаблонов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_patterns_2 = [('Hy-Vee', 'Hy-Vee'), \n",
    "                    (\"Smokin' Joe's\", \"Smokin' Joe's\"),\n",
    "                    ('Central City', 'Central City'),\n",
    "                    ('Costco Wholesale', 'Costco Wholesale'),\n",
    "                    ('Walmart', 'Walmart'), \n",
    "                    ('Wal-Mart', 'Walmart'),\n",
    "                    ('Fareway Stores', 'Fareway Stores'),\n",
    "                    (\"Casey's\", \"Casey's General Store\"),\n",
    "                    (\"Sam's Club\", \"Sam's Club\"), \n",
    "                    ('Kum & Go', 'Kum & Go'),\n",
    "                    ('CVS', 'CVS Pharmacy'), \n",
    "                    ('Walgreens', 'Walgreens'),\n",
    "                    ('Yesway', 'Yesway Store'),\n",
    "                    ('Target Store', 'Target'),\n",
    "                    ('Quik Trip', 'Quik Trip'), \n",
    "                    ('Circle K', 'Circle K'),\n",
    "                    ('Hometown Foods', 'Hometown Foods'),\n",
    "                    (\"Bucky's\", \"Bucky's Express\"), \n",
    "                    ('Kwik', 'Kwik Shop')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преимущество этого решения состоит в том, что поддерживать данный список намного проще, чем в предыдущем примере `store_patterns`.\n",
    "\n",
    "Другое изменение, которое я внес с помощью функции `generalize`, заключается в том, что исходное значение будет сохранено, если не указано значение по умолчанию. Теперь вместо использования `combine_first` функция `generalize` позаботится обо всем. \n",
    "\n",
    "Наконец, я отключил сопоставление регулярных выражений по умолчанию для улучшения производительности.\n",
    "\n",
    "Теперь, когда все данные настроены, вызвать их очень просто:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Store_Group_2'] = generalize(df['Store Name'], store_patterns_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как насчет производительности?\n",
    "\n",
    "    15.5 s ± 409 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "Немного медленнее, но думаю, что это более элегантное решение и я бы использовал его в будущем.\n",
    "\n",
    "Обратной стороной этого подхода является то, что он предназначен для очистки строк. Решение `np.select` более полезно, поскольку его можно применять и к числовым значениям.\n",
    "\n",
    "### А как насчет типов данных?\n",
    "\n",
    "В последних версиях *pandas* есть специальный тип `string`. Я попытался преобразовать `Store Name` в строковый тип *pandas*, чтобы увидеть, есть ли улучшение производительности. Никаких изменений не заметил. Однако не исключено, что в будущем скорость будет повышена, так что имейте это в виду.\n",
    "\n",
    "Тип `category` показал многообещающие результаты. \n",
    "\n",
    "> Обратитесь к моей [предыдущей статье](https://dfedorov.spb.ru/pandas/%D0%98%D1%81%D0%BF%D0%BE%D0%BB%D1%8C%D0%B7%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5%20%D1%82%D0%B8%D0%BF%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85%20%D0%BA%D0%B0%D1%82%D0%B5%D0%B3%D0%BE%D1%80%D0%B8%D0%B8%20%D0%B2%20pandas.html) за подробностями о типе данных категории.\n",
    "\n",
    "Можем преобразовать данные в тип `category` с помощью `astype`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Store Name'] = df['Store Name'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь повторно запустите пример `np.select` точно так же, как мы делали ранее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Store_Group_3'] = np.select(store_criteria, store_values, None)\n",
    "df['Store_Group_3'] = df['Store_Group_1'].combine_first(df['Store Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    786 ms ± 108 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "Мы перешли с `13` до менее `1 секунды`, сделав одно простое изменение. Удивительно!\n",
    "\n",
    "Причина, по которой это произошло, довольно проста. Когда *pandas* преобразует столбец в категориальный тип, функция `str.contains()` будет вызываться для каждого уникального текстового значения. Поскольку этот набор данных содержит много повторяющихся данных, мы получаем огромный прирост производительности.\n",
    "\n",
    "Посмотрим, работает ли это для нашей функции `generalize`:\n",
    "\n",
    "    df['Store_Group_4'] = generalize(df['Store Name'], store_patterns_2)\n",
    "\n",
    "К сожалению, получаем ошибку:\n",
    "\n",
    "    ValueError: Cannot setitem on a Categorical with a new category, set the categories first\n",
    "\n",
    "Эта ошибка подчеркивает некоторые проблемы, с которыми я сталкивался в прошлом при работе с категориальными (*Categorical*) данными. При *merging* и *joining* категориальных данных вы можете столкнуться с подобными типами проблем.\n",
    "\n",
    "Я попытался найти хороший способ изменить работу `generalize()`, но не смог. \n",
    "\n",
    "Тем не менее есть способ воспроизвести категориальный подход (*Category approach*), построив [таблицу поиска](https://ru.wikipedia.org/wiki/%D0%A2%D0%B0%D0%B1%D0%BB%D0%B8%D1%86%D0%B0_%D0%BF%D0%BE%D0%B8%D1%81%D0%BA%D0%B0) (*lookup table*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Таблица поиска\n",
    "\n",
    "Как мы узнали из категориального подхода, данный набор содержит много повторяющихся данных. \n",
    "\n",
    "Мы можем построить таблицу поиска и запустить ресурсоемкую функцию только один раз для каждой строки.\n",
    "\n",
    "Чтобы проиллюстрировать, как это работает со строками, давайте преобразуем значение обратно в строковый тип вместо категории:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Store Name'] = df['Store Name'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Invoice/Item Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Store Number</th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Store Location</th>\n",
       "      <th>County Number</th>\n",
       "      <th>County</th>\n",
       "      <th>...</th>\n",
       "      <th>Bottle Volume (ml)</th>\n",
       "      <th>State Bottle Cost</th>\n",
       "      <th>State Bottle Retail</th>\n",
       "      <th>Bottles Sold</th>\n",
       "      <th>Sale (Dollars)</th>\n",
       "      <th>Volume Sold (Liters)</th>\n",
       "      <th>Volume Sold (Gallons)</th>\n",
       "      <th>Store_Group_1</th>\n",
       "      <th>Store_Group_2</th>\n",
       "      <th>Store_Group_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INV-16681900011</td>\n",
       "      <td>01/02/2019</td>\n",
       "      <td>5286</td>\n",
       "      <td>Sauce</td>\n",
       "      <td>108, College</td>\n",
       "      <td>Iowa City</td>\n",
       "      <td>52240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>JOHNSON</td>\n",
       "      <td>...</td>\n",
       "      <td>200</td>\n",
       "      <td>6.24</td>\n",
       "      <td>9.36</td>\n",
       "      <td>24</td>\n",
       "      <td>224.64</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.26</td>\n",
       "      <td>Sauce</td>\n",
       "      <td>Sauce</td>\n",
       "      <td>Sauce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INV-16681900027</td>\n",
       "      <td>01/02/2019</td>\n",
       "      <td>5286</td>\n",
       "      <td>Sauce</td>\n",
       "      <td>108, College</td>\n",
       "      <td>Iowa City</td>\n",
       "      <td>52240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>JOHNSON</td>\n",
       "      <td>...</td>\n",
       "      <td>500</td>\n",
       "      <td>11.50</td>\n",
       "      <td>17.25</td>\n",
       "      <td>12</td>\n",
       "      <td>207.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.58</td>\n",
       "      <td>Sauce</td>\n",
       "      <td>Sauce</td>\n",
       "      <td>Sauce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INV-16681900018</td>\n",
       "      <td>01/02/2019</td>\n",
       "      <td>5286</td>\n",
       "      <td>Sauce</td>\n",
       "      <td>108, College</td>\n",
       "      <td>Iowa City</td>\n",
       "      <td>52240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>JOHNSON</td>\n",
       "      <td>...</td>\n",
       "      <td>375</td>\n",
       "      <td>3.21</td>\n",
       "      <td>4.82</td>\n",
       "      <td>24</td>\n",
       "      <td>115.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.37</td>\n",
       "      <td>Sauce</td>\n",
       "      <td>Sauce</td>\n",
       "      <td>Sauce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INV-16685400036</td>\n",
       "      <td>01/02/2019</td>\n",
       "      <td>2524</td>\n",
       "      <td>Hy-Vee Food Store / Dubuque</td>\n",
       "      <td>3500 Dodge St</td>\n",
       "      <td>Dubuque</td>\n",
       "      <td>52001.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>DUBUQUE</td>\n",
       "      <td>...</td>\n",
       "      <td>1000</td>\n",
       "      <td>4.17</td>\n",
       "      <td>6.26</td>\n",
       "      <td>12</td>\n",
       "      <td>75.12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.17</td>\n",
       "      <td>Hy-Vee</td>\n",
       "      <td>Hy-Vee</td>\n",
       "      <td>Hy-Vee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INV-16690300035</td>\n",
       "      <td>01/02/2019</td>\n",
       "      <td>4449</td>\n",
       "      <td>Kum &amp; Go #121 / Urbandale</td>\n",
       "      <td>12041 Douglas Pkwy</td>\n",
       "      <td>Urbandale</td>\n",
       "      <td>50322.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.0</td>\n",
       "      <td>POLK</td>\n",
       "      <td>...</td>\n",
       "      <td>375</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.79</td>\n",
       "      <td>24</td>\n",
       "      <td>66.96</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.37</td>\n",
       "      <td>Kum &amp; Go</td>\n",
       "      <td>Kum &amp; Go</td>\n",
       "      <td>Kum &amp; Go</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Invoice/Item Number        Date  Store Number                   Store Name  \\\n",
       "0     INV-16681900011  01/02/2019          5286                        Sauce   \n",
       "1     INV-16681900027  01/02/2019          5286                        Sauce   \n",
       "2     INV-16681900018  01/02/2019          5286                        Sauce   \n",
       "3     INV-16685400036  01/02/2019          2524  Hy-Vee Food Store / Dubuque   \n",
       "4     INV-16690300035  01/02/2019          4449    Kum & Go #121 / Urbandale   \n",
       "\n",
       "              Address       City  Zip Code Store Location  County Number  \\\n",
       "0        108, College  Iowa City   52240.0            NaN           52.0   \n",
       "1        108, College  Iowa City   52240.0            NaN           52.0   \n",
       "2        108, College  Iowa City   52240.0            NaN           52.0   \n",
       "3       3500 Dodge St    Dubuque   52001.0            NaN           31.0   \n",
       "4  12041 Douglas Pkwy  Urbandale   50322.0            NaN           77.0   \n",
       "\n",
       "    County  ...  Bottle Volume (ml) State Bottle Cost  State Bottle Retail  \\\n",
       "0  JOHNSON  ...                 200              6.24                 9.36   \n",
       "1  JOHNSON  ...                 500             11.50                17.25   \n",
       "2  JOHNSON  ...                 375              3.21                 4.82   \n",
       "3  DUBUQUE  ...                1000              4.17                 6.26   \n",
       "4     POLK  ...                 375              1.86                 2.79   \n",
       "\n",
       "  Bottles Sold  Sale (Dollars) Volume Sold (Liters)  Volume Sold (Gallons)  \\\n",
       "0           24          224.64                  4.8                   1.26   \n",
       "1           12          207.00                  6.0                   1.58   \n",
       "2           24          115.68                  9.0                   2.37   \n",
       "3           12           75.12                 12.0                   3.17   \n",
       "4           24           66.96                  9.0                   2.37   \n",
       "\n",
       "   Store_Group_1  Store_Group_2  Store_Group_3  \n",
       "0          Sauce          Sauce          Sauce  \n",
       "1          Sauce          Sauce          Sauce  \n",
       "2          Sauce          Sauce          Sauce  \n",
       "3         Hy-Vee         Hy-Vee         Hy-Vee  \n",
       "4       Kum & Go       Kum & Go       Kum & Go  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала мы создаем `DataFrame` поиска, который содержит все уникальные значения, и запускаем функцию `generalize`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_df = pd.DataFrame()\n",
    "lookup_df['Store Name'] = df['Store Name'].unique()\n",
    "lookup_df['Store_Group_5'] = generalize(lookup_df['Store Name'], store_patterns_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Store_Group_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sauce</td>\n",
       "      <td>Sauce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hy-Vee Food Store / Dubuque</td>\n",
       "      <td>Hy-Vee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kum &amp; Go #121 / Urbandale</td>\n",
       "      <td>Kum &amp; Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IDA Liquor</td>\n",
       "      <td>IDA Liquor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lake View Foods</td>\n",
       "      <td>Lake View Foods</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Store Name    Store_Group_5\n",
       "0                        Sauce            Sauce\n",
       "1  Hy-Vee Food Store / Dubuque           Hy-Vee\n",
       "2    Kum & Go #121 / Urbandale         Kum & Go\n",
       "3                   IDA Liquor       IDA Liquor\n",
       "4              Lake View Foods  Lake View Foods"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем объединить (*merge*) его обратно в окончательный `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, lookup_df, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1.38 s ± 15.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "Он работает медленнее, чем подход `np.select` для категориальных данных, но влияние на производительность может быть уравновешено более простой читабельностью для ведения списка поиска.\n",
    "\n",
    "Кроме того, промежуточный `lookup_df` может стать отличным выходом для аналитика, который поможет очистить больше данных. Эту экономию можно измерить часами работы!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Резюме\n",
    "\n",
    "[Этот](https://counting.substack.com/p/data-cleaning-is-analysis-not-grunt) информационный бюллетень Рэнди Ау (*Randy Au*) - хорошее обсуждение важности очистки данных и отношения любви / ненависти, которое многие специалисты по данным чувствуют при выполнении данной задачи. Я согласен с предположением Рэнди о том, что очистка данных - это анализ.\n",
    "\n",
    "По моему опыту, вы можете многое узнать о своих базовых данных, взяв на себя действия по очистке, описанные в этой статье.\n",
    "\n",
    "Я подозреваю, что в ходе повседневного анализа вы найдете множество случаев, когда вам нужно очистить текст, аналогично тому, что я показал выше.\n",
    "\n",
    "Вот краткое изложение рассмотренных решений:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Решение   |Время исполнения   |Примечания   |\n",
    "|---|---|---|\n",
    "|`np.select`   | `13 с` |Может работать для нетекстового анализа   |\n",
    "|`generalize`  | `15 с` |Только текст   |\n",
    "|Категориальные данные и `np.select`   |`786 мс`  |Категориальные данные могут быть сложными при *merging* и *joining*   |\n",
    "|Таблица поиска и `generalize`   | `1.3 с` |Таблица поиска может поддерживаться кем-то другим|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для некоторых наборов данных производительность не является проблемой, поэтому выбирайте то, что вам ближе.\n",
    "\n",
    "Однако по мере увеличения размера данных (представьте, что вы проводите анализ для `50` штатов), вам нужно будет понять, как эффективно использовать *pandas* для очистки текста. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
