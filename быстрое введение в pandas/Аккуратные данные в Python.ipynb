{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Аккуратные данные в Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/dm-fedorov/pandas_basic/blob/master/быстрое%20введение%20в%20pandas/Аккуратные%20данные%20в%20Python.ipynb\" target=\"_blank\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Оригинал статьи доступен по [ссылке](http://www.jeannicholashould.com/tidy-data-in-python.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://t.me/init_python\"><img src=\"https://dfedorov.spb.ru/pandas/logo-telegram.png\" width=\"35\" height=\"35\" alt=\"telegram\" align=\"left\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Недавно я наткнулся на статью Хэдли Уикхэма (*Hadley Wickham*) под названием [*Tidy Data*](http://vita.had.co.nz/papers/tidy-data.pdf) (Аккуратные Данные). \n",
    "\n",
    "Документ, опубликованный еще в 2014 году, посвящен одному аспекту очистки данных, упорядочиванию: структурированию наборов данных для упрощения анализа. В документе Уикхэм демонстрирует, как любой набор данных может быть структурирован до проведения анализа. Он подробно описывает различные типы наборов данных и способы их преобразования в стандартный формат.\n",
    "\n",
    "Очистка данных - одна из самых частых задач в области науки о данных. Независимо от того, с какими данными вы имеете дело или какой анализ вы выполняете, в какой-то момент вам придется очистить данные. Приведение данных в порядок упрощает работу в будущем. \n",
    "\n",
    "> Библиотеки для построения графиков [`Altair`](https://dfedorov.spb.ru/pandas/%D0%92%D0%B2%D0%B5%D0%B4%D0%B5%D0%BD%D0%B8%D0%B5%20%D0%B2%20%D0%B2%D0%B8%D0%B7%D1%83%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8E%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85%20%D1%81%20%D0%BF%D0%BE%D0%BC%D0%BE%D1%89%D1%8C%D1%8E%20Altair.html) и `Plotly` на входе принимают фреймы данных в аккуратном формате.\n",
    "\n",
    "В этой заметке я обобщу некоторые примеры наведения порядка, которые Уикхэм использует в своей статье, и продемонстрирую, как это сделать с помощью *Python* и  *pandas*.\n",
    "\n",
    "## Определение аккуратных данных\n",
    "Структура, которую Уикхэм определяет как аккуратная (*tidy*), имеет следующие атрибуты:\n",
    "\n",
    "- Каждая переменная (`variable`) образует столбец и содержит значения (`values`).\n",
    "- Каждое наблюдение (`observation`) образует строку.\n",
    "- Каждый объект наблюдения (`observational unit`) составляет таблицу.\n",
    "\n",
    "Несколько определений:\n",
    "\n",
    "- *Переменная*: измерение или атрибут. Рост, вес, пол и т. д.\n",
    "- *Значение*: фактическое измерение или атрибут. 152 см, 80 кг, самка и др.\n",
    "- *Наблюдение*: все значения измеряются на одном объекте. Каждый человек.\n",
    "\n",
    "Пример беспорядочного набора данных (*messy dataset*):\n",
    "\n",
    "![](https://github.com/dm-fedorov/pandas_basic/blob/master/pic/not_tidy.jpg?raw=true)\n",
    "\n",
    "Пример аккуратного набора данных (*tidy dataset*):\n",
    "\n",
    "![](https://github.com/dm-fedorov/pandas_basic/blob/master/pic/tidy.jpg?raw=true)\n",
    "\n",
    "## Убираем беспорядочные наборы данных\n",
    "С помощью следующих примеров, взятых из статьи Уикхема, мы преобразуем беспорядочные наборы данных в аккуратный формат. Цель здесь не в том, чтобы проанализировать наборы данных, а, скорее, в их стандартизированной подготовке перед анализом. \n",
    "\n",
    "Рассмотрим пять типов беспорядочных наборов данных:\n",
    "\n",
    "    1) Заголовки столбцов - это значения, а не имена переменных.\n",
    "    2) Несколько переменных хранятся в одном столбце.\n",
    "    3) Переменные хранятся как в строках, так и в столбцах.\n",
    "    4) В одной таблице хранятся несколько единиц объектов наблюдения (observational units).\n",
    "    5) Одна единица наблюдения хранится в нескольких таблицах.\n",
    "\n",
    "### Заголовки столбцов - это значения, а не имена переменных\n",
    "\n",
    "**Набор данных Pew Research Center**\n",
    "\n",
    "Этот набор данных исследует взаимосвязь между доходом и религией.\n",
    "\n",
    "Проблема: заголовки столбцов состоят из возможных значений дохода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://github.com/dm-fedorov/pandas_basic/blob/master/data/tidy_data/pew-raw.csv?raw=True\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аккуратная версия этого набора данных - та, в которой значения дохода будут не заголовками столбцов, а значениями в столбце дохода. Чтобы привести в порядок этот набор данных, нам нужно его растопить (*melt*). \n",
    "\n",
    "В библиотеке *pandas* есть встроенная функция [`melt`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html), которая позволяет это сделать.\n",
    "\n",
    "Она \"переворачивает\" (*unpivots*) фрейм данных (*DataFrame*) из широкого формата (*wide format*) в длинный (*long format*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_df = pd.melt(df, [\"religion\"], var_name=\"income\", value_name=\"freq\")\n",
    "formatted_df = formatted_df.sort_values(by=[\"religion\"])\n",
    "\n",
    "# выводим аккуратную версию набора данных:\n",
    "formatted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Набор данных Billboard Top 100**\n",
    "\n",
    "Этот набор данных представляет собой еженедельный рейтинг песен с момента их попадания в [*Billboard Top 100*](https://ru.wikipedia.org/wiki/Billboard_Hot_100) до последующих 75 недель.\n",
    "\n",
    "Проблемы:\n",
    "\n",
    "- Заголовки столбцов состоят из значений: номер недели (`x1st.week`,…)\n",
    "- Если песня находится в Топ-100 менее 75 недель, оставшиеся столбцы заполняются пропущенными значениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://github.com/dm-fedorov/pandas_basic/blob/master/data/tidy_data/billboard.csv?raw=True\", \n",
    "                 encoding=\"mac_latin2\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для приведения этих данных к аккуратным мы снова растопим (*melt*) столбцы недель в один столбец `date`. \n",
    "\n",
    "Создадим одну строку в неделю для каждой записи. Если данных за данную неделю нет, то строку создавать не будем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melting\n",
    "id_vars = [\"year\", \"artist.inverted\", \"track\", \"time\", \"genre\", \"date.entered\", \"date.peaked\"]\n",
    "\n",
    "df = pd.melt(frame=df, id_vars=id_vars, var_name=\"week\", value_name=\"rank_\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"week\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Форматирование \n",
    "df[\"week\"] = df['week'].str.extract('(\\d+)', expand=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаление ненужных строк\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем столбцы \"date\"\n",
    "df['date'] = pd.to_datetime(df['date.entered']) + pd.to_timedelta(df['week'], unit='w') - pd.DateOffset(weeks=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"year\", \"artist.inverted\", \"track\", \"time\", \"genre\", \"week\", \"rank_\", \"date\"]]\n",
    "df = df.sort_values(ascending=True, by=[\"year\", \"artist.inverted\", \"track\", \"week\", \"rank_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"rank\"] = df[\"rank_\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"rank_\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Назначение аккуратного набора данных переменной billboard для использования в будущем\n",
    "billboard = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По-прежнему часто повторяются детали песни: `track`, `time` и `genre`. \n",
    "\n",
    "По этой причине набор данных все еще не совсем аккуратный в соответствии с определением Уикхема. Мы рассмотрим его снова в следующем примере."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Несколько типов в одной таблице\n",
    "\n",
    "Следуя за набором данных *Billboard*, рассмотрим проблему повторения из предыдущей таблицы.\n",
    "\n",
    "Проблемы:\n",
    "\n",
    "- Несколько единиц наблюдения (`track` и ее `rank`) в одной таблице.\n",
    "\n",
    "Сначала создадим таблицу песен, которая будет содержать сведения о каждой песне:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_cols = [\"year\", \"artist.inverted\", \"track\", \"time\", \"genre\"]\n",
    "songs = billboard[songs_cols].drop_duplicates()\n",
    "songs = songs.reset_index(drop=True)\n",
    "songs[\"song_id\"] = songs.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем создадим таблицу `ranks`, которая будет содержать только `song_id`, `date` и `rank`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = pd.merge(billboard, songs, on=[\"year\", \"artist.inverted\", \"track\", \"time\", \"genre\"])\n",
    "ranks = ranks[[\"song_id\", \"date\", \"rank\"]]\n",
    "ranks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Несколько переменных хранятся в одном столбце\n",
    "\n",
    "**Записи по туберкулёзу от Всемирной организации здравоохранения**\n",
    "\n",
    "Этот набор данных документирует количество подтвержденных случаев туберкулеза по странам, годам, возрасту и полу.\n",
    "\n",
    "Проблемы:\n",
    "\n",
    "- Некоторые столбцы содержат несколько значений: пол (`m` или `f`) и возраст (`0–14`, `15–24`, `25–34`, `45–54`, `55–64`, `65`, `unknown`).\n",
    "- Смесь нулей и пропущенных значений `NaN`. Это связано с процессом сбора данных, и для этого набора данных важно различие."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://github.com/dm-fedorov/pandas_basic/blob/master/data/tidy_data/tb-raw.csv?raw=True\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы привести в порядок этот набор данных, нужно удалить значения из заголовка и преобразовать их в строки. \n",
    "\n",
    "Сначала нужно расплавить (*melt*) столбцы, содержащие пол и возраст. Как только у нас будет единственный столбец, мы получим из него три столбца: `sex`, `age_lower` и `age_upper`. \n",
    "\n",
    "Затем с их помощью сможем правильно построить аккуратный набор данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.melt(df, id_vars=[\"country\", \"year\"], value_name=\"cases\", var_name=\"sex_and_age\")\n",
    "\n",
    "# Извлечь пол, нижнюю границу возраста и группу верхней границы возраста\n",
    "tmp_df = df[\"sex_and_age\"].str.extract(\"(\\D)(\\d+)(\\d{2})\", expand=False)    \n",
    "\n",
    "# Столбцы имени\n",
    "tmp_df.columns = [\"sex\", \"age_lower\", \"age_upper\"]\n",
    "\n",
    "# Создайте столбец age на основе age_lower и age_upper\n",
    "tmp_df[\"age\"] = tmp_df[\"age_lower\"] + \"-\" + tmp_df[\"age_upper\"]\n",
    "\n",
    "# Merge \n",
    "df = pd.concat([df, tmp_df], axis=1)\n",
    "\n",
    "# Удалите ненужные столбцы и строки\n",
    "df = df.drop(['sex_and_age', \"age_lower\", \"age_upper\"], axis=1)\n",
    "df = df.dropna()\n",
    "df = df.sort_values(ascending=True,by=[\"country\", \"year\", \"sex\", \"age\"])\n",
    "\n",
    "# В результате получается аккуратный набор данных\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переменные хранятся как в строках, так и в столбцах\n",
    "**Набор сетевых данных по глобальной исторической климатологии (Global Historical Climatology Network Dataset)**\n",
    "\n",
    "Этот набор данных представляет собой ежедневные записи погоды для метеостанции (*MX17004*) в Мексике за пять месяцев в 2010 году.\n",
    "\n",
    "Проблемы:\n",
    "\n",
    "- Переменные хранятся как в строках (`tmin`, `tmax`), так и в столбцах (`days`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://github.com/dm-fedorov/pandas_basic/blob/master/data/tidy_data/weather-raw.csv?raw=True\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.melt(df, id_vars=[\"id\", \"year\", \"month\", \"element\"], var_name=\"day_raw\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы упорядочить этот набор данных, мы хотим переместить три неуместных переменных (`tmin`, `tmax` и `days`) в виде трех отдельных столбцов: `tmin`, `tmax` и `date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Извлекаем день\n",
    "df[\"day\"] = df[\"day_raw\"].str.extract(\"d(\\d+)\", expand=False)  \n",
    "df[\"id\"] = \"MX17004\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# К числовым значениям\n",
    "df[[\"year\", \"month\", \"day\"]] = df[[\"year\", \"month\", \"day\"]].apply(lambda x: pd.to_numeric(x, errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание даты из разных столбцов\n",
    "def create_date_from_year_month_day(row):\n",
    "    return datetime.datetime(year=row[\"year\"], month=int(row[\"month\"]), day=row[\"day\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date\"] = df.apply(lambda row: create_date_from_year_month_day(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['year', \"month\", \"day\", \"day_raw\"], axis=1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unmelting столбец \"element\"\n",
    "df = df.pivot_table(index=[\"id\", \"date\"], columns=\"element\", values=\"value\")\n",
    "df.reset_index(drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Один тип в нескольких таблицах\n",
    "**Набор данных: имена мальчиков в штате Иллинойс за 2014/15 годы**\n",
    "\n",
    "Проблемы:\n",
    "\n",
    "- Данные распределены по нескольким таблицам/файлам.\n",
    "- В имени файла присутствует переменная `year`.\n",
    "\n",
    "Чтобы загрузить разные файлы в один `DataFrame`, мы можем запустить собственный скрипт, который будет добавлять файлы вместе. Кроме того, нам нужно будет извлечь переменную `year` из имени файла."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Следующий пример подразумевает наличие двух файлов в корневой директории: `2015-baby-names-illinois.csv` и `2014-baby-names-illinois.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/dm-fedorov/pandas_basic/master/data/tidy_data/2015-baby-names-illinois.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/dm-fedorov/pandas_basic/master/data/tidy_data/2014-baby-names-illinois.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year(string):\n",
    "    match = re.match(\".+(\\d{4})\", string) \n",
    "    if match != None: \n",
    "        return match.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '.' # текущая директория\n",
    "\n",
    "allFiles = glob.glob(path + \"/201*-baby-names-illinois.csv\")\n",
    "\n",
    "frame = pd.DataFrame()\n",
    "df_list= []\n",
    "\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_, index_col=None, header=0)\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    df[\"year\"] = extract_year(file_)\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заключительные мысли\n",
    "\n",
    "В этой заметке я сосредоточился только на одном аспекте статьи Уикхема, а именно на части манипулирования данными. Моей главной целью было продемонстрировать манипуляции с данными в Python. Важно отметить, что в [статье Уикхема](http://vita.had.co.nz/papers/tidy-data.pdf) есть значительный раздел, посвященный инструментам и визуализациям, с помощью которых вы можете извлечь пользу, приведя в порядок свой набор данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://t.me/init_python\"><img src=\"https://dfedorov.spb.ru/pandas/logo-telegram.png\" width=\"35\" height=\"35\" alt=\"telegram\" align=\"left\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
