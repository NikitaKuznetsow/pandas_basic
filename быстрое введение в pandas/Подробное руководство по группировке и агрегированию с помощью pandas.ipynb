{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подробное руководство по группировке и агрегированию с помощью pandas\n",
    "\n",
    "<a href=\"https://t.me/init_python\"><img src=\"https://dfedorov.spb.ru/pandas/logo-telegram.png\" width=\"35\" height=\"35\" alt=\"telegram\" align=\"left\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/dm-fedorov/pandas_basic/blob/master/быстрое%20введение%20в%20pandas/Подробное%20руководство%20по%20группировке%20и%20агрегированию%20с%20помощью%20pandas.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\" target=\"_blank\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна из базовых функций анализа данных - группировка и агрегирование. В некоторых случаях этого уровня анализа может быть достаточно, чтобы ответить на вопросы бизнеса. В других случаях - это может стать первым шагом в более сложном анализе. \n",
    "\n",
    "В pandas функцию [`groupby`](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html) можно комбинировать с одной или несколькими функциями агрегирования, чтобы быстро и легко обобщать данные. Эта концепция обманчиво проста и большинство новых пользователей pandas поймут ее. Однако они удивятся тому, насколько полезными могут стать функции агрегирования для проведения сложного анализа данных. \n",
    "\n",
    "В этом Блокноте кратко изложены основные функции агрегирования pandas и показаны примеры более сложных настраиваемых агрегаций. Независимо от того, являетесь ли вы начинающим или опытным пользователем pandas, я думаю, вы узнаете что-то новое для себя.\n",
    "\n",
    "Оригниал статьи Криса [тут](https://pbpython.com/groupby-agg.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Агрегирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В контексте даннной статьи *функция агрегирования* - это функция, которая принимает несколько отдельных значений и возвращает сводные данные. В большинстве случаев возвращаемые данные представляют собой одно значение.\n",
    "\n",
    "Наиболее распространенные функции агрегирования - это *простое среднее* (simple average) или *суммирование* (summation) значений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее представлен пример расчета суммарной и средней стоимости билетов для набора данных \"Титаник\", загруженного из пакета [seaborn](https://seaborn.pydata.org/examples/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *15 апреля 1912 года самый большой пассажирский лайнер в истории во время своего первого рейса столкнулся с айсбергом. Когда Титаник затонул, погибли 1502 из 2224 пассажиров и членов экипажа. Эта сенсационная трагедия потрясла международное сообщество и привела к улучшению правил безопасности для судов. Одна из причин, по которой кораблекрушение привело к гибели людей, заключалась в том, что не хватало спасательных шлюпок для пассажиров и экипажа. Несмотря на то, что в выживании после затопления была определенная доля удачи, некоторые группы людей имели больше шансов выжить, чем другие*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждая строка набора данных представляет одного человека. Столбцы описывают различные атрибуты, включая то, выжили ли они (`survived`), их возраст (`age`), класс пассажира (`pclass`), пол (`sex`) и стоимость проезда (`fare`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fare'].agg(['sum', 'mean']) # сумма и среднее по столбцу стоимости билета, здесь передаем список агрегирующих функций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта простая концепция - необходимый строительный блок для более сложного анализа. \n",
    "\n",
    "Одна из областей, которую необходимо обсудить, - это то, что существует несколько способов вызова функции агрегирования. Как показано выше, вы можете передать *список функций* для применения к одному или нескольким столбцам данных.\n",
    "\n",
    "Что, если вы хотите выполнить анализ только подмножества столбцов? \n",
    "\n",
    "Есть два других варианта агрегирования: *использование словаря* и *именованное агрегирование* (named aggregation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование словаря:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.agg({'fare': ['sum', 'mean'],\n",
    "        'sex' : ['count']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование кортежей (именованное агрегирование):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.agg(fare_sum=('fare', 'sum'),\n",
    "       fare_mean=('fare', 'mean'),\n",
    "       sex_count=('sex', 'count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важно знать об этих параметрах и понимать, какой из них и когда использовать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Я предпочитаю использовать словари для агрегирования.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подход с кортежами ограничен возможностью применять только одно агрегирование за раз к определенному столбцу. Если мне нужно переименовать столбцы, я буду использовать функцию [`rename`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html) после завершения агрегации. В некоторых случаях подход со списком является более рациональным. Тем не менее, я повторю, что, на мой взгляд, словарный подход обеспечивает наиболее надежный способ для большинства ситуаций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда мы знаем, как использовать агрегацию, мы можем объединить это с [`groupby`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) для резюмирования данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основы математики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наиболее распространенными встроенными функциями агрегирования являются базовые математические функции, включая *сумму* (sum), *среднее значение* (mean), *медианное значение* (median), *минимум* (minimum), *максимум* (maximum), *стандартное отклонение* (standard deviation), *дисперсию* (variance), *среднее абсолютное отклонение* (mean absolute deviation) и *произведение* (product)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем применить все эти функции к `fare` (стоимости проезда) при группировке по `embark_town` (городу посадки на корабль):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func_math = {\n",
    "    'fare': ['sum', 'mean', 'median', 'min', 'max', 'std', 'var', 'mad', 'prod']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['embark_town']).agg(agg_func_math).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это все относительно простая математика.\n",
    "\n",
    "Кстати, я не нашел подходящего варианта использования функции [`prod`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.prod.html), которая вычисляет произведение всех значений в группе, и включил ее для полноты картины.\n",
    "\n",
    "Еще один полезный трюк - использовать [`describe`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) для одновременного выполнения нескольких встроенных агрегаторов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func_describe = {'fare': ['describe']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['embark_town']).agg(agg_func_describe).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подсчет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После базовой математики *подсчет* (counting) является следующим наиболее распространенным агрегированием, которое я выполняю для сгруппированных данных. \n",
    "\n",
    "Он несколько сложнее, чем простая математика. Вот три примера подсчета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func_count = {'embark_town': ['count', 'nunique', 'size']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['deck']).agg(agg_func_count) # статистика по палубам Титаника"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Главное отличие, о котором следует помнить, заключается в том, что `count` не включает значения `NaN`, тогда как `size` их включает. В зависимости от набора данных это различие может оказаться полезным. \n",
    "\n",
    "Кроме того, функция `nunique` исключит значения `NaN` из уникальных счетчиков. \n",
    "\n",
    "Продолжайте читать, чтобы увидеть пример того, как включить `NaN` в подсчет уникальных значений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Первый и последний"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В следующем примере мы можем выбрать самую высокую и самую низкую стоимость билета в зависимости от города, в котором совершили посадку пассажиры Титаника. \n",
    "\n",
    "Следует помнить один важный момент: вы должны сначала отсортировать данные, если хотите, чтобы в качестве `first` (первого) и `last` (последнего) были выбраны максимальное и минимальное значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func_selection = {'fare': ['first', 'last']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['fare'], ascending=False).groupby(['embark_town']).agg(agg_func_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В приведенном выше примере я бы рекомендовал использовать `max` и `min`, но для полноты картины включил `first` и `last`. В других приложениях (например, при анализе временных рядов) вы можете выбрать значения `first` и `last` для дальнейшего анализа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другой подход к выбору - использовать `idxmax` и `idxmin` для выбора значения индекса, соответствующего максимальному или минимальному значениям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func_max_min = {'fare': ['idxmax', 'idxmin']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['embark_town']).agg(agg_func_max_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем проверить результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[258, 378]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот еще один трюк, который можно использовать для просмотра строк с максимальной стоимостью проезда (`fare`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.groupby('class')['fare'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведенный выше пример - одно из тех мест, где агрегирование на основе списка является полезным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Другие библиотеки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы не ограничены функциями агрегирования в pandas. К примеру, можно использовать функции статистики из [`scipy`](https://docs.scipy.org/doc/scipy/reference/stats.html) или [`numpy`](https://numpy.org/doc/stable/reference/routines.statistics.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот пример расчета *моды* (`mode`) и *асимметрии* (`skew`) данных для стоимости проезда."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func_stats = {'fare': [skew, mode, pd.Series.mode]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['embark_town']).agg(agg_func_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересны результаты вычисления *моды* (`mode`). Функция [`mode`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mode.html) из [`scipy.stats`](https://docs.scipy.org/doc/scipy/reference/stats.html) возвращает наиболее часто встречающееся значение, а также количество вхождений. Если вам просто нужно наиболее частое значение, то используйте [`pd.Series.mode`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.mode.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ключевым моментом является то, что вы можете использовать любую функцию, которую хотите, если она знает, как интерпретировать массив значений pandas и возвращает одно значение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с текстом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При работе с текстом функции подсчета будут работать должным образом. Вы также можете использовать функцию `mode` из `scipy` для текстовых данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одно интересное приложение состоит в том, что если у вас небольшое количество различных значений, то можете использовать питоновскую функцию [`set`](https://docs.python.org/3/tutorial/datastructures.html#sets) для отображения списка уникальных значений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующая краткая сводка для `class` (класса каюты) и `deck` (палубы) показывает, как данный подход можно использовать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func_text = {'deck': ['nunique', mode, set]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['class']).agg(agg_func_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пользовательские функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стандартные функции агрегирования pandas и функции из экосистемы Python удовлетворят многие ваши потребности в анализе данных. Однако вы, вероятно, захотите создать свои собственные пользовательские функции агрегирования. Есть четыре способа для создания собственных функций. \n",
    "\n",
    "Чтобы проиллюстрировать различия, давайте вычислим *25-й процентиль данных* (также называемый квантилью .25 или нижней квартилью), используя четыре подхода."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во-первых, мы можем использовать функцию [`partial`](https://docs.python.org/3/library/functools.html#functools.partial):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_25 = partial(pd.Series.quantile, q=0.25) # возвращает обортку над pd.Series.quantile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_25.__name__ = '25%' # пойдет в наименование будущего столбца"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем мы определяем нашу собственную функцию (которая представляет собой небольшую обертку для [`quantile`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.quantile.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile_25(x):\n",
    "    return x.quantile(.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее определяем лямбда-функцию и даем ей имя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_25 = lambda x: x.quantile(.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_25.__name__ = 'lambda_25%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем задаем встроенную (inline) лямбду и формируем словарь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func = {\n",
    "    'fare': [q_25, percentile_25, lambda_25, lambda x: x.quantile(.25)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['embark_town']).agg(agg_func).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видите, результаты одинаковые, но названия столбцов немного отличаются. Это область предпочтений программистов, но я рекомендую ознакомиться с вариантами, поскольку вы встретите большинство из них в онлайн-решениях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Я предпочитаю использовать собственные функции или встроенные (inline) лямбды.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и во многих других областях программирования - это элемент стиля и предпочтений, но я рекомендую вам выбрать один или два подхода и придерживаться их для единообразия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примеры пользовательских функций "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как показано выше, существует несколько подходов к разработке пользовательских функций агрегирования. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В большинстве случаев функции представляют собой легкие обертки (wrappers) для встроенных функций pandas. Они нужны, т.к. нет возможности передать аргументы в агрегаты (aggregations). \n",
    "\n",
    "Следующие примеры должны пояснить этот момент."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы хотите подсчитать количество нулевых значений, вы можете использовать эту [функцию](https://medium.com/escaletechblog/writing-custom-aggregation-functions-with-pandas-96f5268a8596):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nulls(s):\n",
    "    return s.size - s.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы хотите включить значения `NaN` в свои уникальные счетчики, вам необходимо указать параметр `dropna=False` у функции [`nunique`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.nunique.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_nan(s):\n",
    "    return s.nunique(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот результат применения всех функций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func_custom_count = {\n",
    "    'embark_town': ['count', 'nunique', 'size', unique_nan, count_nulls, set]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['deck']).agg(agg_func_custom_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы хотите рассчитать *90-й процентиль*, используйте [`quantile`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.quantile.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile_90(x):\n",
    "    return x.quantile(.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы хотите вычислить *усеченное среднее* (trimmed mean) значение, из которого исключен самый низкий 10-й процент, используйте функцию [`trim_mean`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.trim_mean.html) из `scipy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import trim_mean\n",
    "\n",
    "def trim_mean_10(x):\n",
    "    return trim_mean(x, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы хотите получить наибольшее значение, независимо от порядка сортировки (см. ранее в этом Блокноте о `first` и `last`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest(x):\n",
    "    return x.nlargest(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это эквивалентно `max`, но я приведу еще один пример с `nlargest` ниже, чтобы подчеркнуть разницу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее я уже [писал](https://pbpython.com/styling-pandas.html) о [`sparkline`](https://pypi.org/project/sparklines/). Обратитесь к этой статье за инструкциями по установке. \n",
    "\n",
    "Вот как включить их в агрегатную функцию для уникального представления данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install sparklines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparklines import sparklines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sparkline_str(x):\n",
    "    bins = np.histogram(x)[0]\n",
    "    sl = ''.join(sparklines(bins))\n",
    "    return sl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот они все вместе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func_largest = {\n",
    "    'fare': [percentile_90, trim_mean_10, largest, sparkline_str]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['class', 'embark_town']).agg(agg_func_largest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции `nlargest` и `nsmallest` могут быть полезны для резюмирования данных в различных сценариях. \n",
    "\n",
    "Следующий код показывает суммарную стоимость для 10 первых и 10 последних пассажиров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_10_sum(x):\n",
    "    return x.nlargest(10).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottom_10_sum(x):\n",
    "    return x.nsmallest(10).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func_top_bottom_sum = {\n",
    "    'fare': [top_10_sum, bottom_10_sum]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('class').agg(agg_func_top_bottom_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование этого подхода может быть полезно для применения [закона Парето](https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%BA%D0%BE%D0%BD_%D0%9F%D0%B0%D1%80%D0%B5%D1%82%D0%BE) к вашим собственным данным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пользовательские функции с несколькими столбцами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у вас есть сценарий, в котором небходимо запустить несколько агрегаций по столбцам, то вы можете использовать `groupby` в сочетании с `apply`, как описано в этом [ответе на stack overflow](https://stackoverflow.com/questions/14529838/apply-multiple-functions-to-multiple-groupby-columns/47103408#47103408)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя этот метод, вы получите доступ ко всем столбцам данных и сможете выбрать подходящий способ агрегирования для создания итогового `DataFrame` (включая наименование столбцов):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(x):\n",
    "    result = {\n",
    "        'fare_sum': x['fare'].sum(),\n",
    "        'fare_mean': x['fare'].mean(),\n",
    "        'fare_range': x['fare'].max() - x['fare'].min()\n",
    "    }\n",
    "    return pd.Series(result).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['class']).apply(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование `apply` с `groupby` дает максимальную гибкость. Однако есть и обратная сторона. Функция `apply` работает медленно, поэтому этот подход следует использовать с осторожностью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с групповыми объектами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После группировки и агрегирования данных вы можете выполнять дополнительные вычисления для сгруппированных объектов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В следующем примере определим, какой процент от общего количества проданных билетов можно отнести к каждой комбинации `embark_town` и `class`. \n",
    "\n",
    "Мы используем метод [`assign()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.assign.html) и лямбда-функцию для добавления столбца `pct_total`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['embark_town', 'class']).agg({'fare': 'sum'}).assign(pct_total=lambda x: x / x.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следует отметить, что можно сделать проще с использованием кросс-таблицы [`pd.crosstab`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.crosstab.html), как описано в [статье](https://pbpython.com/pandas-crosstab.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['embark_town'],\n",
    "            df['class'],\n",
    "            values=df['fare'],\n",
    "            aggfunc='sum',\n",
    "            normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока мы говорим о `crosstab` (кросс-таблицах), полезно иметь в виду, что функции агрегации также можно комбинировать со сводными таблицами (pivot tables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот небольшой пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(data=df,\n",
    "               index=['embark_town'],\n",
    "               columns=['class'],\n",
    "               aggfunc=agg_func_top_bottom_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда необходимо выполнить множество группировок (multiple groupby), чтобы ответить на вопрос. Например, если мы хотим увидеть кумулятивную сумму стоимости билетов, мы можем сгруппировать и агрегировать по городу (town) и классу (class), затем сгруппировать полученный объект и вычислить кумулятивную сумму (cumulative sum):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_group = df.groupby(['embark_town', 'class']).agg({'fare': 'sum'})\n",
    "fare_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_group.groupby(level=0).cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это может быть сложным для понимания. Вот краткое пояснение того, что мы делаем:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/dm-fedorov/pandas_basic/master/pic/multiple-groupby.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример с данными о продажах\n",
    "\n",
    "В следующем примере резюмируем ежедневные данные о продажах и преобразуем их в совокупное ежедневное и ежеквартальное представление. \n",
    "\n",
    "Обратитесь к [статье о Grouper](https://pbpython.com/pandas-grouper-agg.html), если вы не знакомы с использованием метода [`pd.Grouper()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Grouper.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом примере мы хотим включить сумму ежедневных продаж, а также совокупную (cumulative) сумму за квартал:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_excel('https://github.com/chris1610/pbpython/blob/master/data/2018_Sales_Total_v2.xlsx?raw=True')\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sales = sales.groupby([pd.Grouper(key='date', freq='D')]).agg(daily_sales=('ext price', 'sum')).reset_index()\n",
    "daily_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sales['quarter_sales'] = daily_sales.groupby(pd.Grouper(key='date', freq='Q')).agg({'daily_sales': 'cumsum'})\n",
    "daily_sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы получить хорошее представление о том, что происходит, вам нужно взглянуть на границу квартала (с конца марта по начало апреля):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/dm-fedorov/pandas_basic/master/pic/cumulative_total.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы хотите просто получить совокупный (cumulative) квартальный итог, вы можете связать несколько функций `groupby`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала сгруппируйте ежедневные результаты, затем сгруппируйте эти результаты по кварталам и используйте кумулятивную сумму:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# веселый пример :)\n",
    "\n",
    "sales.groupby(\n",
    "    [pd.Grouper(key='date', \n",
    "                freq='D')]).agg(\n",
    "                             daily_sales=('ext price', \n",
    "                                          'sum')).groupby(\n",
    "                                                    pd.Grouper(freq='Q')).agg(\n",
    "                                                                     {'daily_sales': 'cumsum'}).rename(\n",
    "                                                                                                 columns={'daily_sales': 'quarterly_sales'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом примере я включил именованный подход агрегации (named aggregation approach), чтобы переименовать переменную и уточнить, что теперь это ежедневные продажи. Затем я снова группирую и использую совокупную (cumulative) сумму, чтобы получить текущую сумму за квартал. Наконец, я переименовал столбец в квартальные продажи (quarterly sales). \n",
    "\n",
    "По отзывам, на первый взгляд, это сложно понять. Однако, если выполните по шагам, т.е. построите функцию и будете проверять результаты на каждом шаге, то начнете понимать ее. \n",
    "\n",
    "Не расстраивайтесь!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сглаживание иерархических индексов столбцов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию pandas в сводном `DataFrame` создает иерархический индекс у столбца:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['embark_town', 'class']).agg({'fare': ['sum', 'mean']}).round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В какой-то момент в процессе анализа вы, вероятно, захотите «сгладить» (flatten) столбцы, чтобы получилась одна строка с именами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я обнаружил, что мне лучше всего подходит следующий подход. \n",
    "\n",
    "Я использую параметр `as_index=False` при группировке, а затем создаю новое имя свернутого (collapsed) столбца.\n",
    "\n",
    "Вот код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_df = df.groupby(['embark_town', 'class'], as_index=False).agg({'fare': ['sum', 'mean']})\n",
    "multi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_df.columns = ['_'.join(col).rstrip('_') for col in multi_df.columns.values]\n",
    "multi_df.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот изображение, показывающее, как выглядит сплющенный кадр данных:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/dm-fedorov/pandas_basic/master/pic/column_flatten.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я предпочитаю использовать `_` в качестве разделителя, но вы можете использовать другие значения. Просто имейте в виду, что для последующего анализа будет проще, если в именах результирующих столбцов нет пробелов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Промежуточные итоги"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы хотите добавить промежуточные итоги (subtotal), я рекомендую пакет [`sidetable`](https://github.com/chris1610/sidetable).\n",
    "\n",
    "Инструкция по работе с `sidetable` на русском языке [тут](http://dfedorov.spb.ru/pandas/%D0%A1%D0%B2%D0%BE%D0%B4%D0%BD%D0%B0%D1%8F%20%D1%82%D0%B0%D0%B1%D0%BB%D0%B8%D1%86%D0%B0%20%D0%B2%20pandas.html).\n",
    "\n",
    "Вот как вы можете суммировать `fares` по `class`, `embark_town` и `sex` с промежуточным итогом на каждом уровне, а также общим итогом внизу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install sidetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sidetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['class', 'embark_town', 'sex']).agg({'fare': 'sum'}).stb.subtotal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sidetable` также позволяет настраивать уровни промежуточных итогов и итоговые метки. Обратитесь к [документации пакета](https://github.com/chris1610/sidetable) для получения дополнительных примеров того, как `sidetable` может резюмировать данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Резюме"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спасибо, что прочитали эту статью. Здесь много деталей, но это связано с тем, что существует множество различных применений для группировки и агрегирования данных с помощью pandas. Я надеюсь, что этот пост станет полезным ресурсом, который вы сможете добавить в закладки и вернуться к нему, когда столкнетесь с собственной сложной проблемой.\n",
    "\n",
    "Если у вас есть другие распространенные техники, которые вы часто используете, дайте мне знать в комментариях к [статье](https://pbpython.com/groupby-agg.html). Если я получу что-нибудь полезное, я включу его в этот пост или как обновленную статью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
